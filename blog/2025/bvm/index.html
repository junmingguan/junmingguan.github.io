<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Bernstein-von Mises Theorem | Junming Guan </title> <meta name="author" content="Junming Guan"> <meta name="description" content="Proof of Bernstein-von Mises Theorem"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://junmingguan.github.io/blog/2025/bvm/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Junming</span> Guan </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Bernstein-von Mises Theorem</h1> <p class="post-meta"> Created in April 30, 2025 , last updated in November 29, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/bayesian-statistics"> <i class="fa-solid fa-hashtag fa-sm"></i> bayesian-statistics</a>   <a href="/blog/tag/statistics"> <i class="fa-solid fa-hashtag fa-sm"></i> statistics</a>   <a href="/blog/tag/math"> <i class="fa-solid fa-hashtag fa-sm"></i> math</a>   ·   <a href="/blog/category/notes"> <i class="fa-solid fa-tag fa-sm"></i> notes</a> </p> </header> <article class="post-content"> <div id="table-of-contents"> <ul id="toc" class="section-nav"> <li class="toc-entry toc-h3"> <a href="#lemma-103-in-van-der-vaart--lemma-235-in-szab%C3%B3-and-van-der-vaart">Lemma 10.3 in van der Vaart / lemma 2.35 in Szabó and van der Vaart</a> <ul> <li class="toc-entry toc-h4"><a href="#the-range-of-m_n--sqrtn-leq-vert-theta-theta_0vert--leq-epsilon">The range of \(M_n / \sqrt{n} \leq \Vert \theta-\theta_0\Vert \leq \epsilon\)</a></li> <li class="toc-entry toc-h4"><a href="#the-range-of-vert-theta-theta_0vert---epsilon">The range of \(\Vert \theta-\theta_0\Vert &gt; \epsilon\)</a></li> </ul> </li> <li class="toc-entry toc-h3"><a href="#proof-of-lemma-232-in-szab%C3%B3-and-van-der-vaart">Proof of Lemma 2.32 in Szabó and van der Vaart</a></li> <li class="toc-entry toc-h3"> <a href="#BvM">Proof of Theorem 2.16 (Bernstein-von Mises) in Szabó and van der Vaart</a> <ul> <li class="toc-entry toc-h4"><a href="#details-on-step-1">Details on step 1</a></li> <li class="toc-entry toc-h4"><a href="#details-on-step-2">Details on step 2</a></li> </ul> </li> <li class="toc-entry toc-h3"><a href="#references">References</a></li> </ul> </div> <hr> <div id="markdown-content"> <p style="display:none"> $$ \newcommand{\R}{\mathbb{R}} \newcommand{\EE}{\mathbb{E}} $$ </p> <p>These notes aim to fill in the gaps (potentially trivial to others) in the proof of the Bernstein-von Mises Theorem found in van der Vaart’s <strong>Asymptotic Statistics</strong> <a class="citation" href="#vaart1998asymptotic">(van der Vaart, 1998)</a> and in Szabó and van der Vaart’s <strong>Bayesian statistics</strong> lecture notes <a class="citation" href="#szabo2023bayesian">(Szabó &amp; van der Vaart, 2023)</a>.</p> <div class="definition" id="def-dqm" text="Differentiability in quadratic mean (DQM)"> <p>A family \(\{P_\theta\}_{\theta\in \Theta}\) is differentiable in quadratic mean (DQM) if for every \(\theta\) in the interior of \(\Theta \subset \RR^d\), there exists a vector-valued measurable function \(\dot{\ell}_\theta: \mathfrak{X}\mapsto \RR^d\) such that, as \(h\to0\),</p> \[\begin{equation} \int \Big[ p_{\theta+h}^{1/2} - p_\theta^{1/2} - \frac{1}{2} h^\top \dot{\ell}_\theta p_\theta^{1/2}\Big]^2 \, d\mu = \mathcal{o}(\|h\|^2). \label{ass:dqm} \end{equation}\] </div> <p>The Bernstein-von Mises Theorem is as follows:</p> <div class="theorem" id="thm-bvm" text="Bernstein-von Mises (Thoerem 2.16 in Szabó and van der Vaart)"> <p>Suppose that for some compact neighborhood \(\Theta_0 \subset \Theta\) of \(\theta_0\), there exists a sequence of tests $\phi_n$ such that</p> \[\begin{equation} P^n_{\theta_0} \phi_n \to 0, \qquad \qquad \sup_{\theta \notin \Theta_0} P_\theta^n (1- \phi_n) \to 0. \label{ass:test-cond} \end{equation}\] <p>Furthermore, assume that $\eqref{ass:dqm}$ holds at every \(\theta\) in the interior of \(\Theta\) with nonsingular Fisher information, and that the map \(\theta\mapsto P_\theta\) is one-to-one. If \(\theta_0\) is an inner point of \(\Theta\) and the prior measure is absolutely continuous with a bounded density that is continuous and positive in a neighborhood of \(\theta_0\), then the corresponding posterior distributions satisfy</p> \[\Bigg\| \Pi(\sqrt{n}(\theta-\theta_0) \in \cdot \mid X_1,\dots,X_n) - N_d(I_{\theta_0}^{-1} \Delta_{n,\theta_0}, I^{-1}_{\theta_0}) \Bigg\|_{TV} \stackrel{P^n_{\theta_0}}{\rightarrow}0,\] <p>where \(\Delta_{n,\theta_0} = \frac{1}{\sqrt{n}} \sum_{i=1}^n \dot{\ell}_\theta(X_i)\) converges under \(\theta_0\) in distribution to a \(N_d(0, I_{\theta_0})\)-distribution.</p> </div> <h3 id="lemma-103-in-van-der-vaart--lemma-235-in-szabó-and-van-der-vaart">Lemma 10.3 in van der Vaart / lemma 2.35 in Szabó and van der Vaart</h3> <hr> <p>We first look at the proof of the following intermediate result.</p> <div class="lemma" id="lem-exp-test" text="Tests with an exponential rate (lemma 10.3 in van der Vaart / lemma 2.35 in Szabó and van der Vaart)"> <p>Under the conditions of <span class="autoref" data-target="thm-bvm"></span>, there exists for every \(M_n\to \infty\) a sequence of tests \(\phi_n\) and a constant $c &gt; 0$ such that, for every sufficiently large $n$ and every \(\|\theta -\theta_0\| \geq M_n / \sqrt{n}\),</p> \[\begin{equation*} P^n_{\theta_0} \phi_n \to 0, \qquad \qquad .P^n_{\theta} (1- \phi_n) \leq e^{-cn (\|\theta-\theta_0\|^2 \wedge 1)}. \end{equation*}\] </div> <p>The goal is to define a sequence of test \(\omega_n\) such that \(P^n_{\theta_0} \omega_n \to 0\) and \(P^n_{\theta} (1-\omega_n) \to 0\) exponentially fast.</p> <p>The proof proceeds by dividing the parameter space \(\Theta\) into the two disjoint sets, and define a test sequence for each.</p> <h4 id="the-range-of-m_n--sqrtn-leq-vert-theta-theta_0vert--leq-epsilon">The range of \(M_n / \sqrt{n} \leq \Vert \theta-\theta_0\Vert \leq \epsilon\)</h4> <hr style="width:40%; text-align:left; margin-left:0;"> <p>They define \(\omega_n = \mathbb{1}\{\Vert (\mathbb{P}_n-P_{\theta_0})\dot{\ell}^L_{\theta_0}\Vert \geq \sqrt{M_n/n}\}\), and claim that \(P^n_{\theta_0} \omega_n \to 0\) (covergence in probability) via CLT. To see this, note that CLT implies</p> \[\sqrt{n} (\mathbb{P}_n-P_{\theta_0})\dot{\ell}^L_{\theta_0} \rightsquigarrow \mathcal{N}(0, \text{Var}(\dot{\ell}^L_{\theta_0})).\] <p>This holds because \(\dot{\ell}^L_{\theta_0} = \mathbb{1}\{\Vert \dot{\ell}_{\theta_0}\Vert \leq L\} \dot{\ell}_{\theta_0}\) is bounded and thus has finite second moment. This means that</p> \[(\mathbb{P}_n-P_{\theta_0})\dot{\ell}^L_{\theta_0} = \mathcal{O}_{P_{\theta_0}}\Big(\frac{1}{\sqrt{n}}\Big).\] <p>Since \(1=\mathcal{o}_{P_{\theta_0}}(\sqrt{M_n})\). By \(M_n \to \infty\), we also have</p> \[\begin{align*} (\mathbb{P}_n-P_{\theta_0})\dot{\ell}^L_{\theta_0} = \mathcal{O}_{P_{\theta_0}}\Big(\frac{1}{\sqrt{n}}\Big)\mathcal{o}_{P_{\theta_0}}(\sqrt{M_n}) = \mathcal{o}_{P_{\theta_0}}\left(\sqrt{\frac{M_n}{n}}\right) . \end{align*}\] <p>That is, \(P^n_{\theta_0}\omega_n\) converges in probability to 0:</p> \[\mathbb{P}^n_{\theta_0}\left[\Vert (\mathbb{P}_n-P_{\theta_0})\dot{\ell}^L_{\theta_0}\Vert \geq \sqrt{\frac{M_n}{n}}\right] = \mathbb{P}^n_{\theta_0} \omega_n \to 0.\] <p>we then need to show the type-II error converges to 0 exponentially fast. A left-out detail regards the claim</p> \[P_\theta \dot{\ell}^L_{\theta_0} - P_{\theta_0} \dot{\ell}^L_{\theta_0} = (P_{\theta} \dot{\ell}^L_{\theta_0} \dot{\ell}^\top_{\theta_0} +o(1)) (\theta - \theta_0),\] <p>which holds due to the DQM assumption (<span class="autoref" data-target="def-dqm"></span>). To see this, recall that DGM means there exists \(\dot{\ell}_{\theta_0}\) such that</p> \[\int \left[ \sqrt{p_{\theta}} - \sqrt{p_{\theta_0}} - \frac{1}{2}\dot{\ell}_{\theta_0}^\top (\theta-\theta_0) \sqrt{p_{\theta_0}} \right]^2 d\mu = o(\Vert \theta-\theta_0\Vert ^2).\] <p>That implies the following expansion:</p> \[\begin{aligned} p_{\theta} &amp;= (\sqrt{p_{\theta}})^2 = (\sqrt{p_{\theta_0}} + \frac{1}{2}\dot{\ell}_{\theta_0}^\top (\theta-\theta_0) \sqrt{p_{\theta_0}} + r_{\theta} )^2 \\ &amp;= p_{\theta_0} + p_{\theta_0} \dot{\ell}_{\theta_0}^\top (\theta-\theta_0) + \text{} \\ &amp; \quad \quad r^2_{\theta} + \frac{1}{4} p_{\theta_0} (\dot{\ell}_{\theta_0}^\top (\theta-\theta_0))^2 + 2\sqrt{p_{\theta_0}} r_{\theta} + \dot{\ell}_{\theta_0}^\top (\theta-\theta_0) \sqrt{p_{\theta_0}} r_\theta, \end{aligned}\] <p>where \(\Vert r_\theta(x)\Vert _{L_2} =\int r^2_{\theta}(x)d\mu(x)= o(\Vert \theta-\theta_0\Vert )\). If we apply the integral operator \(\int (\cdot)\dot{\ell}^L_{\theta_0}d\mu\) to both sides, we will get an expression similar to the desired, with some extra terms. We analyze the exta terms one by one:</p> \[\left\Vert \int r^2_\theta \dot{\ell}^L_{\theta_0}d\mu\right\Vert \leq \int \left\Vert r^2_\theta\dot{\ell}^L_{\theta_0}\right\Vert d\mu \leq \int r^2_\theta \left\Vert \dot{\ell}^L_{\theta_0}\right\Vert d\mu \leq \int L r^2_{\theta} d\mu = o(\Vert \theta-\theta_0\Vert ^2) = o(\Vert \theta-\theta_0\Vert );\] \[\begin{aligned} \left\Vert \int p_{\theta_0} (\dot{\ell}_{\theta_0}^\top (\theta-\theta_0))^2 \dot{\ell}_{\theta_0}^L d\mu \right\Vert &amp;\leq \int p_{\theta_0} (\dot{\ell}_{\theta_0}^\top (\theta-\theta_0))^2\left\Vert \dot{\ell}_{\theta_0}^L\right\Vert d\mu \leq \int p_{\theta_0} \Vert \theta-\theta_0\Vert ^2 \left\Vert \dot{\ell}_{\theta_0} \right\Vert ^2 \left\Vert \dot{\ell}_{\theta_0}^L \right\Vert d\mu \\ &amp; = \Vert \theta-\theta_0\Vert ^2 \cdot \mathbb{E}_{P_{\theta_0}} \left[\left\Vert \dot{\ell}_{\theta_0} \right\Vert ^3 \mathbb{1}\left\{\left\Vert \dot{\ell}_{\theta_0} \right\Vert \leq L\right\}\right] \\ &amp;=\mathcal{O}(\Vert \theta-\theta_0\Vert ^2) = o(\Vert \theta-\theta_0\Vert ), \end{aligned}\] <p>because the random variable \(\left\Vert \dot{\ell}_{\theta_0} \right\Vert\) is bounded and thus has finite third moment;</p> \[\left|\int \sqrt{p_{\theta_0}} r_{\theta} d\mu\right| \leq \int\sqrt{p_{\theta_0}} \left| r_{\theta}\right| d\mu \leq \int p_{\theta_0} d\mu \cdot \Vert r_{\theta}\Vert _{L_2} = o(\Vert \theta-\theta_0\Vert ^2) = o(\Vert \theta-\theta_0\Vert );\] \[\begin{aligned} \left\Vert \int \dot{\ell}_{\theta_0}^L \dot{\ell}_{\theta_0}^\top (\theta-\theta_0) \sqrt{p_{\theta_0}} r_{\theta}d\mu \right\Vert &amp;\leq \int \left\Vert \dot{\ell}_{\theta_0}^L\right\Vert \left| \dot{\ell}_{\theta_0}^\top (\theta-\theta_0)\right| \sqrt{p_{\theta_0}} |r_{\theta}| d\mu \leq \int \left\Vert \dot{\ell}_{\theta_0}^L\right\Vert ^2 \left\Vert \theta-\theta_0\right\Vert \sqrt{p_{\theta_0}} |r_{\theta}| d\mu \\ &amp;\leq \Vert \theta-\theta_0 \Vert \cdot \mathbb{E}_{P_{\theta_0}}\left[ \left\Vert \dot{\ell}_{\theta_0}^L\right\Vert ^4 \right]^\frac{1}{2} \int r_{\theta}^2 d\mu \\ &amp; = o(\Vert \theta-\theta_0\Vert )\cdot \mathcal{O}(\Vert \theta-\theta_0\Vert ) \\ &amp;= o(\Vert \theta-\theta_0\Vert ^2) \\ &amp;= o(\Vert \theta-\theta_0\Vert ). \end{aligned}\] <p>Thus, we have</p> \[\begin{aligned} P_{\theta} \dot{\ell}_{\theta_0}^L &amp;= P_{\theta_0}\dot{\ell}_{\theta_0}^L + P_{\theta_0}\dot{\ell}_{\theta_0}^L \dot{\ell}_{\theta_0}^\top (\theta-\theta_0) + o(\Vert \theta-\theta_0\Vert ) \\ &amp;=P_{\theta_0}\dot{\ell}_{\theta_0}^L + (P_{\theta_0}\dot{\ell}_{\theta_0}^L \dot{\ell}_{\theta_0}^\top + o(1))(\theta-\theta_0). \end{aligned}\] <p>Note that the \(o(1)\) term is some square matrix, say \(A_h\), with \(o(1)\) entries that depends on \(h:=\theta-\theta_0\). Then we have</p> \[\sigma_{\rm{min}}(P_{\theta_0}\dot{\ell}_{\theta_0}^L \dot{\ell}_{\theta_0}^\top+A_h) \geq \sigma_{\rm{min}}(P_{\theta_0}\dot{\ell}_{\theta_0}^L \dot{\ell}_{\theta_0}^\top) - \sigma_{\rm{max}}(A_h).\] <p>\(P_{\theta_0}\dot{\ell}_{\theta_0}^L \dot{\ell}_{\theta_0}^\top\) is nonsingular, so \(\sigma_{\rm{min}}(P_{\theta_0}\dot{\ell}_{\theta_0}^L \dot{\ell}_{\theta_0}^\top)&gt;c_0\) for some postive \(c_0\). Also, for for every \(\theta\) that is sufficiently close to \(\theta_0\), say, \(\Vert h\Vert \leq \epsilon\), we have \(\sigma_{\rm{max}}(A_h)=\Vert A_h-0\Vert _2 \leq c_1 &lt; c_0\) for some positive \(c_1\). Pick \(c \leq c_0 - c_1\), we have</p> \[\left\Vert P_{\theta} \dot{\ell}_{\theta_0}^L - P_{\theta_0}\dot{\ell}_{\theta_0}^L\right\Vert = \left\Vert (P_{\theta_0}\dot{\ell}_{\theta_0}^L \dot{\ell}_{\theta_0}^\top + A_h)(\theta-\theta_0)\right\Vert \geq \sigma_{\rm{min}}(P_{\theta_0}\dot{\ell}_{\theta_0}^L \dot{\ell}_{\theta_0}^\top+A_h) \geq c\Vert \theta-\theta_0\Vert .\] <p>Moving on, if \(\omega_n = 0\), we have \(-\Vert (\mathbb{P}_n-P_{\theta_0})\dot{\ell}^L_{\theta_0}\Vert &gt; -\sqrt{M_n/n}\). So</p> \[\left\Vert (\mathbb{P}_n - P_\theta) \dot{\ell}_{\theta_0}^L \right\Vert \geq \left\Vert (P_{\theta_0} - P_\theta) \dot{\ell}_{\theta_0}^L \right\Vert - \left\Vert (\mathbb{P}_n - P_{\theta_0}) \dot{\ell}_{\theta_0}^L \right\Vert &gt; c\Vert \theta-\theta_0\Vert -\sqrt{M_n/n}.\] <p>For \(c\Vert \theta-\theta_0\Vert \geq 2 \sqrt{M_n/n}\), i.e., \(-c\Vert \theta-\theta_0\Vert / 2\leq -\sqrt{M_n/n}\), we have</p> \[\left\Vert (\mathbb{P}_n - P_\theta) \dot{\ell}_{\theta_0}^L \right\Vert \geq \frac{c}{2}\Vert \theta-\theta_0\Vert .\] <p>Since \(\Vert \cdot \Vert _2 \leq \sqrt{d} \Vert \cdot \Vert _\infty\), with a union bound, we have</p> \[\begin{aligned} P^n_{\theta} (1-\omega_n) &amp;\leq P_\theta \left[ \left\Vert (\mathbb{P}_n - P_\theta) \dot{\ell}_{\theta_0}^L \right\Vert \geq \frac{c}{2}\Vert \theta-\theta_0\Vert \right] \\ &amp;\leq P_\theta \left[ \left\Vert (\mathbb{P}_n - P_\theta) \dot{\ell}_{\theta_0}^L \right\Vert _\infty \geq \frac{c}{2\sqrt{d}}\Vert \theta-\theta_0\Vert \right] \\ &amp;\leq \sum_{i=1}^d P_\theta \left[ \left| (\mathbb{P}_n - P_\theta) \dot{\ell}_{\theta_0;i}^L \right| \geq \frac{c}{2\sqrt{d}}\Vert \theta-\theta_0\Vert \right] \\ &amp;\leq 2d e^{-n\frac{c^2}{8dL^2} \Vert \theta-\theta_0\Vert ^2} \\ &amp;= \exp\left\{-n\frac{c^2}{8L^2 d} \Vert \theta-\theta_0\Vert ^2+\log 2d\right\}. \end{aligned}\] <p>We want \(C_1\) such that</p> \[\exp\left\{-n\frac{c^2}{8L^2 d} \Vert \theta-\theta_0\Vert ^2+\log 2d\right\} \leq \exp\left\{-nC_1 \Vert \theta-\theta_0\Vert ^2\right\} .\] <p>Take log on both sides,</p> \[-n\frac{c^2}{8L^2 d} \Vert \theta-\theta_0\Vert ^2+\log 2d \leq -nC_1 \Vert \theta-\theta_0\Vert ^2,\] <p>so we must have</p> \[C_1 \leq \frac{c^2}{8L^2 d} - \frac{\log 2 d }{n \Vert \theta-\theta_0\Vert ^2}.\] <p>For sufficiently large \(n\), since \(c\Vert \theta-\theta_0\Vert \geq 2 \sqrt{M_n/n}\), i.e., \(n\Vert \theta-\theta_0\Vert ^2\geq c^2 M_n/4 \to \infty\), the second term will be negligible. One can pick \(C_1 \leq \frac{c^2}{16L^2 d}\) so that</p> \[\begin{equation*} P^n_{\theta} (1-\omega_n) \leq e^{-nC_1 \Vert \theta-\theta_0\Vert ^2} \leq e^{-c^2M_n^2/4} \end{equation*}\] <p>holds for sufficienly large \(n\).</p> <h4 id="the-range-of-vert-theta-theta_0vert---epsilon">The range of \(\Vert \theta-\theta_0\Vert &gt; \epsilon\)</h4> <hr style="width:40%; text-align:left; margin-left:0;"> <p>This follows from lemma 2.33 in Szabó and van der Vaart by taking \(\Theta_1=\{\Vert \theta-\theta_0\Vert &gt; \epsilon\}\).</p> <div class="lemma" id="lem-test-exp" text="Lemma 2.33 in Szabó and van der Vaart"> <p>If there exits tests \(\phi_n\) such that \(\sup_{\theta\in \Theta_0} P^n_\theta \phi_n \to 0\) and \(\sup_{\theta\in \Theta_1} P^n_\theta (1-\phi_n) \to 0\), for given fixed sets \(\Theta_0\) and \(\Theta_1\) and a given statistical model, then there exist tests \(\psi_n\) and \(c&gt;0\) such that \(\sup_{\theta\in \Theta_0} P^n_\theta \psi_n \leq e^{-cn}\) and \(\sup_{\theta\in \Theta_1} P^n_\theta (1-\psi_n) \leq e^{-cn}\).</p> </div> <h3 id="proof-of-lemma-232-in-szabó-and-van-der-vaart">Proof of Lemma 2.32 in Szabó and van der Vaart</h3> <hr> <p>We next look at the proof of another intermiediate result.</p> <div class="lemma" id="lem-laplace-tran" text="Convergence of Laplace transforms (lemma 2.32 in Szabó and van der Vaart)"> <p>If \(\Delta_n\) are random vectors with \(\Delta_n \rightsquigarrow N_d(0, J)\), then there exists \(M_n \to \infty\) such that \(\Delta_n \mathbb{1}_{\|\Delta_n \|\leq M_n} − \Delta_n → 0\) and, for every $C &gt; 0$,</p> \[\begin{equation} \sup_{\Vert h\Vert &lt;C} \Bigg|\EE e^{h^\top \Delta_n \indicator{\Vert \Delta_n\Vert \leq M_n}-h^\top J h^\top /2}-1\Bigg|\to 0. \label{eq:laplace-tran} \end{equation}\] </div> <p>For \(\Delta \sim {N}(0, J)\), by Chebychev’s inequality,</p> \[\mathbb{P}\left[ \Vert \Delta\Vert &gt; M \right] \leq \frac{\text{Var}(\Vert \Delta\Vert )}{M^2} \stackrel{M \to \infty}{\longrightarrow} 0.\] <p>Since \(\Delta_n \rightsquigarrow \Delta\), by Continuous Mapping Theorem, \(\Vert \Delta_n\Vert \rightsquigarrow \Vert \Delta\Vert\), so</p> \[\mathbb{P}\left[ \Vert \Delta_n\Vert &gt; M \right] \to \mathbb{P}\left[ \Vert \Delta\Vert &gt; M \right].\] <p>It follows that \(\Delta'_n:=\Delta_n \mathbb{1}_{\Vert \Delta_n\Vert \leq M}\) converges in distribution to \(\Delta 1_{\Vert \Delta\Vert \leq M}\). This is because the function \(g(x)=x \mathbb{1}_{\Vert x\Vert \leq M}\) is continuous almost everywhere (the set \(\{\omega: \Vert \Delta(\omega)\Vert = M\}\) has measure \(0\)), and Continous Mapping Thoerem applies.</p> <div class="remark"> <p>An important part of the proof of BvM (details in the <a href="#BvM">next section</a>) is that the truncated version of \(\Delta_n\), \(\Delta_n':=\Delta_n \mathbb{1}\{\Vert \Delta_n\Vert \leq M_n\}\), preserves the distributional limit of \(\Delta_n\).</p> <details> <summary><b><img class="emoji" title=":bulb:" alt=":bulb:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4a1.png" height="20" width="20"> Show details</b> </summary> <div class="proof"> <p>We can write \(\Delta_n' = \Delta_n + (\Delta_n'-\Delta_n)\). The first part \(\leadsto \Delta\) by assumption. The second part \(\stackrel{\mathbb{P}}{\to}0\) by Lemma 2.32. We then argue by Slutsky’s Thoerem.</p> </div> </details> </div> <p>To show $\eqref{eq:laplace-tran}$ we first show it for fixed \(M\). To find a sequence \(M_n\), we rely on the following result.</p> <div class="lemma" id="lem-diag" text="Diagonalization argument"> <p>Suppose \(\lim_{n\to \infty}f(M,n)\to 0\) for every \(M&gt;0\). Then there exists \(M_n\) such that \(f(M_n, n) \to 0\).</p> <details> <summary><b><img class="emoji" title=":bulb:" alt=":bulb:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4a1.png" height="20" width="20"> Show proof</b> </summary> <div class="proof"> <p>For every fixed \(M\), We know that \(\lim_{n\to\infty} f(M, n) \to 0.\)</p> <p>Fix \(M=k\in \mathbb{Z}^+\), there exists \(N_k\) (chosen such that \(\geq N_{k-1}\)) such that \(\vert f(M,n)\vert \leq \frac{1}{k}\) for all \(n\geq N_k\).</p> <p>So now we have two sequences \(M_k\)’s and \(N_k\)’s. To define \(M_n\to \infty\):</p> <ul> <li>For \(N_k \leq n &lt; N_{k+1}\), pick \(M_n:=k\).</li> <li>For \(n &lt; N_1\), pick \(M_1:=1\).</li> </ul> <p>To show that this sequence work, fix \(\delta&gt;0\). Pick an integer \(K\) such that \(1/K \leq \delta\). We have shown there exists \(N_K\) such that \(\vert f(M_n,n)\vert=\vert f(K,n)\vert \leq \frac{1}{K}\) for all \(n \in [N_K, N_{K+1})\); for \(n \in [N_{K+q}, N_{K+q+1})\) for \(q\in\{1, 2, \dots,\}\), we have \(\vert f(M_n,n)\vert =\vert f(K+q,n)\vert \leq \frac{1}{K+q} &lt; \frac{1}{K}\). So we have \(\vert f(M_n,n)\vert \leq \frac{1}{K}\leq \delta\). Since \(\delta\) is arbitrary, we have \(\lim_{n\to\infty} f(M_n, n) = 0.\)</p> </div> </details> </div> <p><span class="autoref" data-target="lem-diag"></span> can also be used to find \(C_n\to \infty\) such that the property holds, with</p> \[f(C,n):=\sup_{\| h\| &lt;C} |\EE e^{h^\top \Delta_n \indicator{\| \Delta_n\| \leq M_n}-h^\top J h^\top /2}-1|.\] <h3 id="BvM">Proof of Theorem 2.16 (Bernstein-von Mises) in Szabó and van der Vaart</h3> <hr> <p>The proof considers a ball in the parameter space: \(\Theta_n = \{\theta: \Vert \theta-\theta_0\Vert &lt; M_n / \sqrt{n}\}\), and argue that (1) the posterior distribution outside of the ball is negligable, and that (2) the posterior measures restricted to this ball</p> \[\begin{equation} \Pi_n(B\mid X^{(n)})=\frac{\int_{\Theta_n \cap (\theta_0+B/\sqrt{n})} \prod (p_\theta / p_{\theta_0}) (X_i)\, d\Pi(\theta)}{\int_{\Theta_n} \prod (p_\theta / p_{\theta_0}) (X_i) \,d\Pi(\theta)} \label{eq:post-mea} \end{equation}\] <p>tends to a Gaussian distribution.</p> <h4 id="details-on-step-1">Details on step 1</h4> <hr style="width:40%; text-align:left; margin-left:0;"> <p>We want to show that \(\Pi(\sqrt{n}(\theta-\theta_0)\in\Theta_n^c \mid X^{(n)})\to 0\) in probability, so it suffices to show that</p> \[\mathbb{E}_{\theta_0}[\Pi(\sqrt{n}(\theta-\theta_0)\in\Theta_n^c \mid X^{(n)})] \to 0\] <p>and then argue by Markov’s inequality.</p> <p>Note that for a sequence of tests \(\phi_n\) whose existence is guaranteed by the assumption:</p> \[\begin{align*} \mathbb{E}_{\theta_0}[\Pi(\sqrt{n}(\theta-\theta_0)\in\Theta_n^c \mid X^{(n)})] &amp;= \mathbb{E}_{\theta_0}[\Pi(\sqrt{n}(\theta-\theta_0)\in\Theta_n^c \mid X^{(n)}) \indicator{A_n}] + \mathbb{E}_{\theta_0}[\Pi(\sqrt{n}(\theta-\theta_0)\in\Theta_n^c \mid X^{(n)})(1-\indicator{A_n})] \\ &amp;\leq \mathbb{E}_{\theta_0}[\Pi(\sqrt{n}(\theta-\theta_0)\in\Theta_n^c \mid X^{(n)}) \phi_n \indicator{A_n}] \\ &amp; \qquad \text{ }+ \mathbb{E}_{\theta_0}[\Pi(\sqrt{n}(\theta-\theta_0)\in\Theta_n^c \mid X^{(n)}) (1-\phi_n) \indicator{A_n}] + \PP_{\theta_0}[A_n^c] \\ &amp; \leq \mathbb{P}_{\theta_0}[\phi_n] + \mathbb{E}_{\theta_0}[\Pi(\sqrt{n}(\theta-\theta_0)\in\Theta_n^c \mid X^{(n)}) \mathbb{1}_{A_n}(1-\phi_n)] + \mathbb{P}_{\theta_0}[A_n^c]\\ &amp;=: \text{I} + \text{II} + \text{III}, \end{align*}\] <p>where \(A_n\) is the event where \(\int \prod (p_\theta /p_{\theta_0}) (X_i) \,d\Pi(\theta) \geq n^{-d/2} \epsilon_n\). This is to control the denominator of \(\eqref{eq:post-mea}\). We need to show \(\mathbb{P}_{\theta_0}[A_n]\to 1\) and that \(\text{II}\) tends to 0.</p> <p>For \(\text{II}\to 0\), we need to pick \(\epsilon_n\to 0\) such that</p> \[\underbrace{\epsilon_n^{-1} \int_{M_n &lt; \Vert h\Vert &lt; \sqrt{n}} e^{-c\Vert h\Vert ^2} \left\Vert \frac{d\Pi}{d\mu}\right\Vert _\infty\,}_{(a)} + \underbrace{n^{d/2} \epsilon_n^{-1} \int_{\|\theta-\theta_0\|\geq 1} e^{-cn} d|pi(\theta)}_{(b)}\to 0.\] <p>Note that \((b) \leq n^{d/2} e^{-cn} \epsilon^{-1}\). By dominated convergence,</p> \[\lim_{n\to \infty}\int_{M_n &lt; \Vert h\Vert &lt; \sqrt{n}} e^{-c\Vert h\Vert ^2} \left\Vert \frac{d\Pi}{d\mu}\right\Vert_\infty\,dh = \int \lim_{n\to \infty} \indicator{M_n &lt; \Vert h\Vert &lt; \sqrt{n}} \,e^{-c\Vert h\Vert^2} \left\Vert \frac{d\Pi}{d\mu}\right\Vert_\infty\,dh = 0.\] <p>So we need \(\epsilon_n\to 0\) more slowly than the above convergence and also more slowly than \(n^{d/2} e^{-cn} \to 0\) for \((a)+(b)\) to go to zero.</p> <h4 id="details-on-step-2">Details on step 2</h4> <hr style="width:40%; text-align:left; margin-left:0;"> <p>We first establish (the fourth paragraph in the original proof)</p> \[\begin{equation} \EE_\theta \sup_B \Bigg| \int_{h\in B:\Vert h\Vert &lt; M_n} \prod \frac{p_{\theta+h/\sqrt{n}}}{p_\theta} (X_i) \,dh - \int_{h\in B:\Vert h\Vert &lt; M_n} e^{h^\top \Delta_{n,\theta}-\frac{1}{2}h^\top I_\theta h}\, dh \Bigg| \to 0. \label{eq:conv-in-mean-sup} \end{equation}\] <p>We need the following converence in mean:</p> \[\begin{equation} \lim_{n\to \infty} \EE_\theta \Bigg| \prod \frac{p_{\theta+h/\sqrt{n}}}{p_\theta} (X_i) - e^{h^\top \Delta_{n,\theta}-\frac{1}{2}h^\top I_\theta h} \Bigg| = 0. \label{eq:conv-in-mean} \end{equation}\] <details> <summary><b><img class="emoji" title=":bulb:" alt=":bulb:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4a1.png" height="20" width="20"> Show proof of $\eqref{eq:conv-in-mean}$</b> </summary> <div class="proof"> <p>Donote \(L_n=\prod \frac{p_{\theta+h/\sqrt{n}}}{p_\theta} (X_i)\). We look at the truncated version \(\Delta_{n, \theta}'=\Delta_{n, \theta} \indicator{\Vert \Delta_{n, \theta}\Vert \leq C_n}\), so that it has all finite moments and the MGF or Laplace transform \(e^{h^\top \Delta_{n, \theta}'-h^\top I_\theta h/2}\) is defined for all \(h\in \mathbb{R}^d\), which is required for later steps. There are four steps:</p> <ul> <li>Show that \(L_n-e^{h^\top \Delta_{n, \theta}'-h^\top I_\theta h/2}\) is uniformly integrable. To do so, we show UI for each of them and argue by triangle inequality. <ul> <li> <em>Note</em>: We need to invoke Lemma 2.32, which requires convergence in first absolute moment. It’s tempting to use Portmanteau’s Lemma, but the exponential function is neither bounded nor Lipschitz, so it doesn’t apply here.</li> </ul> </li> <li>Show that \(L_n-e^{h^\top \Delta_{n, \theta}'-h^\top I_\theta h/2}\leadsto 0\), or \(\stackrel{\PP}{\to}0\).</li> <li>Then argue by the fact that UI + \(\leadsto\) implies \(\stackrel{L_1}{\to}\).</li> </ul> <p><span class="autoref" data-target="lem-laplace-tran"></span> shows that for every \(M\),</p> \[\begin{equation*} \sup_{\Vert h\Vert \leq M} \Big|\EE e^{h^\top \Delta_{n, \theta}'-h^\top I_\theta h/2} - \EE e^{h^\top \Delta_\theta-h^\top I_\theta h/2} \Big|\to 0, \end{equation*}\] <p>where \(\Delta_\theta = N(0, I_\theta^{-1})\). The previous expression means that for any \(h\) such that \(\Vert h\Vert \leq M\)</p> \[\EE e^{h^\top \Delta_{n, \theta}'-h^\top I_\theta h/2} \to \EE e^{h^\top \Delta_\theta-h^\top I_\theta h/2}.\] <p>We have seen that \(\Delta'_{n, \theta} \leadsto \Delta_{\theta}\) in the previous section. By Continous Mapping Theorem, we have that \(e^{h^\top \Delta_{n, \theta}'-h^\top I_\theta h/2} \leadsto e^{h^\top \Delta_\theta-h^\top I_\theta h/2}\). Together with the fact that \(e^{h^\top \Delta_{n, \theta}'-h^\top I_\theta h/2} \geq 0\), by Lemma 2.38, we have that \(e^{h^\top \Delta_{n, \theta}'-h^\top I_\theta h/2}\) is uniformly integrable. Following the logic in the proof, \(L_n\) is uniformly integrable. So \(L_n-e^{h^\top \Delta_{n, \theta}'-\frac{1}{2}h^\top I_\theta h}\) is uniformly integrable. Step 1 is done.</p> <p>Step 2 follows from that fact that \(\Delta_{n, \theta}' \leadsto \Delta_{n, \theta}\) and Continuous Mapping, and LAN.</p> </div> </details> <p>Dominated convergence then implies</p> \[\int_{\| h\| &lt;M} \EE_\theta \Bigg| \prod \frac{p_{\theta+h/\sqrt{n}}}{p_\theta} (X_i) - e^{h^\top \Delta_{n,\theta}-\frac{1}{2}h^\top I_\theta h} \Bigg| \,dh \to 0.\] <p>By Fubini, we have for every measurable \(B\):</p> \[\begin{align*} \int_{\Vert h\Vert &lt;M} \EE_\theta \Bigg| \prod \frac{p_{\theta+h/\sqrt{n}}}{p_\theta} (X_i) - e^{h^\top \Delta_{n,\theta}-\frac{1}{2}h^\top I_\theta h} \Bigg| \,dh &amp;\geq \EE_\theta \int_{\Vert h\Vert &lt;M} \Bigg| \prod \frac{p_{\theta+h/\sqrt{n}}}{p_\theta} (X_i) - e^{h^\top \Delta_{n,\theta}-\frac{1}{2}h^\top I_\theta h} \Bigg| \,dh \\ &amp;\geq \EE_\theta \int_{h\in B:\,\Vert h\Vert &lt;M} \Bigg| \prod \frac{p_{\theta+h/\sqrt{n}}}{p_\theta} (X_i) - e^{h^\top \Delta_{n,\theta}-\frac{1}{2}h^\top I_\theta h} \Bigg| \,dh. \end{align*}\] <p>Then by Jansen’s inequality:</p> \[\begin{align*} \int_{\Vert h\Vert &lt;M} \EE_\theta \Bigg| \prod \frac{p_{\theta+h/\sqrt{n}}}{p_\theta} (X_i) - e^{h^\top \Delta_{n,\theta}-\frac{1}{2}h^\top I_\theta h} \Bigg| \,dh &amp;\geq \EE_\theta \sup_B \int_{h\in B:\,\Vert h\Vert &lt;M} \Bigg| \prod \frac{p_{\theta+h/\sqrt{n}}}{p_\theta} (X_i) - e^{h^\top \Delta_{n,\theta}-\frac{1}{2}h^\top I_\theta h} \Bigg| \,dh \\ &amp;\geq \EE_\theta \sup_B \Bigg\vert \int_{h\in B:\,\Vert h\Vert &lt;M} \prod \frac{p_{\theta+h/\sqrt{n}}}{p_\theta} (X_i) - e^{h^\top \Delta_{n,\theta}-\frac{1}{2}h^\top I_\theta h} \,dh \Bigg\vert . \end{align*}\] <p>So</p> \[\EE_\theta \sup_B \Bigg| \int_{h\in B:\,\Vert h\Vert &lt;M} \prod \frac{p_{\theta+h/\sqrt{n}}}{p_\theta} (X_i) - e^{h^\top \Delta_{n,\theta}-\frac{1}{2}h^\top I_\theta h}\,dh \Bigg| \to 0.\] <p>This holds for each fixed \(M\). One can choose \(M_n\to \infty\) using <span class="autoref" data-target="lem-diag"></span> as before, such that $\eqref{eq:conv-in-mean-sup}$ holds.</p> <p>Now we are ready to show the convergence of $\eqref{eq:post-mea}$ to a Gaussian in total variation distance. To this end, we consider the change of variable \(\sqrt{n}(\theta-\theta_0) \mapsto h\). So $\eqref{eq:post-mea} = Y_n(B)/Y_n(\RR^d)$, where (the factor \(1/\sqrt{n}\) cancels out)</p> \[Y_n(B) = \int_{h\in B:\, \|h\|\leq M_n} \prod \frac{p_{\theta_0+h/\sqrt{n}}}{p_{\theta_0}}(X_i) \frac{\pi(\theta_0+h/\sqrt{n})}{\pi(\theta_0)} \,dh.\] <p>Define</p> \[Z_n(B):= \int_{h\in B:\, \|h\|\leq M_n} e^{h^\top \Delta_{n, \theta_0} - h^\top I_{\theta_0} h/2} \,dh.\] <p>Note \(c_n\) tends in mean to 0 for \(M_n\to \infty\), hence in probability by Markov’s ineqality.</p> <details> <summary><b><img class="emoji" title=":bulb:" alt=":bulb:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4a1.png" height="20" width="20"> Show proof</b> </summary> <div class="proof"> <p>Let \(H_n = I^{-1}_{\theta_0} \Delta_{n, \theta_0} + G\) where \(G\sim N_d(0, I^{-1}_{\theta_0})\).</p> <p>Then we have \(c_n = \PP[ \| H_n \| \geq M_n \mid \Delta_{n, \theta_0} ]\), and we want to show</p> \[\EE[c_n] = \PP[ \| H_n \| \geq M_n ] \to 0.\] <p>Note that \(\{\| H_n \| \geq M_n\} \subset \{\|I^{-1}_{\theta_0} \Delta_{n, \theta_0}\| \geq M_n / 2\} \cup \{\|G\| \geq M_n / 2\}\). Since \(\Delta_{n, \theta_0} \rightsquigarrow N_d(0, I_{\theta_0}^{-1})\) by CLT, we have \(\Delta_{n, \theta_0} = \mathcal{O}_{\PP}(1)\), so \(\PP[\|I^{-1}_{\theta_0} \Delta_{n, \theta_0}\| \geq M_n/2] \to 0\). Similarly, \(\PP[\|G\| \geq M_n/2] \to 0\). Thus, we have</p> \[\EE |c_n| \leq \PP[\|I^{-1}_{\theta_0} \Delta_{n, \theta_0}\| \geq M_n/2] + \PP[\|G\| \geq M_n/2] \to 0.\] </div> </details> <p>Note that the density of \(N_d(I_{\theta_0}^{-1} \Delta_{n, \theta_0} , I_{\theta_0}^{-1})\) is</p> \[\frac{1}{(2\pi)^{d/2} \sqrt{\det I_{\theta_0}^{-1}}} e^{-\frac{1}{2} h^\top I_{\theta_0} h + h^\top \Delta_{n, \theta_0}-\frac{1}{2} \Delta_{n, \theta_0}^\top I_{\theta_0}^{-1} \Delta_{n, \theta_0} }.\] <p>So the quotient</p> \[\frac{Z_n(B)(1-c_n)}{Z_n(\RR^d)} = N_d(I^{-1}_{\theta_0} \Delta_{n, \theta} , I^{-1}_{\theta_0})(B\ \cap\ \{h: \|h\| &lt; M_n\} )= \Phi_{^{-1}_{\theta_0} \Delta_{n, \theta} , I^{-1}_{\theta_0}}(B\ \cap\ \{h: \|h\| &lt; M_n\}),\] <p>which converges to \(\Phi_{^{-1}_{\theta_0} \Delta_{n, \theta} , I^{-1}_{\theta_0}}(B)\) uniformly in $B$. Indeed,</p> \[\Phi_{^{-1}_{\theta_0} \Delta_{n, \theta} , I^{-1}_{\theta_0}}(B) - \Phi_{^{-1}_{\theta_0} \Delta_{n, \theta} , I^{-1}_{\theta_0}}(B\ \cap\ \{h: \|h\| &lt; M_n\}) \leq c_n \to 0,\] <p>where the convergence doesn’t depend on $B$, hence is uniform.</p> <p>In light of this observation, we want to show</p> \[\begin{equation} \sup_B \Bigg| \frac{Z_n(B)}{Z_n(\RR^d)} - \frac{Y_n(B)(1-c_n)}{Y_n(\RR^d)} \Bigg| \to 0. \label{eq:conv-in-TV} \end{equation}\] <p>The two look almost the same due to $\prod \frac{p_{\theta_0+h/\sqrt{n}}}{p_{\theta_0}}(X_i) \approx e^{h^\top \Delta_{\theta_0} - h^\top I_{\theta_0} h/2}$ in mean, as in $\eqref{eq:conv-in-mean-sup}$, except for the extra quotient $\frac{\pi(\theta_0+h/\sqrt{n})}{\pi(\theta_0)}$, which is asymptotically equal to 1. More concretely, if $M_n/\sqrt{n} \to 0$, for any \(h\in \{\|h\| \leq M_n\}\), we have</p> \[\frac{\pi(\theta_0+h/\sqrt{n})}{\pi(\theta_0)} \leq \frac{\pi(\theta_0+M_n/\sqrt{n})}{\pi(\theta_0)} \to 0.\] <p>So</p> \[\sup_{\|h\|\leq M_n}\frac{\pi(\theta_0+h/\sqrt{n})}{\pi(\theta_0)} \to 0.\] <p>As a result, we have</p> \[\begin{equation} \begin{aligned} \sup_B \Bigg|Y_n(B)- \int_{h\in B:\, \|h\|\leq M_n} \prod \frac{p_{\theta_0+h/\sqrt{n}}}{p_{\theta_0}}(X_i) \,dh\Bigg| &amp;= \sup_B \Bigg|\int_{h\in B:\, \|h\|\leq M_n} \prod \frac{p_{\theta_0+h/\sqrt{n}}}{p_{\theta_0}}(X_i) \left(1-\frac{\pi(\theta_0+h/\sqrt{n})}{\pi(\theta_0)} \right)\,dh \Bigg| \\ &amp; \leq \sup_B \Bigg| \int_{h\in B:\, \|h\|\leq M_n} \prod \frac{p_{\theta_0+h/\sqrt{n}}}{p_{\theta_0}}(X_i) \,dh \Bigg| \cdot \sup_{\|h\|\leq M_n} \frac{\pi(\theta_0+h/\sqrt{n})}{\pi(\theta_0)} \to 0. \end{aligned} \label{eq:Yn-with-quotient} \end{equation}\] <p>Now</p> \[Z_n(\mathbb{R}^d) = \frac{(2\pi)^{d/2}}{\sqrt{\det I_{\theta_0}}} e^{\frac{1}{2}\Delta_{n,\theta_0}^T I_{\theta_0}^{-1} \Delta_{n,\theta_0}} (1 - c_n),\qquad c_n = \Phi_{I_{\theta_0}^{-1} \Delta_{n,\theta_0}, I_{\theta_0}^{-1}} (h: \|h\| \ge M_n).\] <p>Observe that</p> \[\Bigg| \frac{Z_n(B)}{Z_n(\RR^d)} - \frac{Y_n(B)(1-c_n)}{Y_n(\RR^d)} \Bigg| = \Bigg| \underbrace{\frac{Z_n(B)-Y_n(B)}{Z_n(\RR^d)}}_{\Lambda_B} - \underbrace{\frac{Z_n(B)}{Z_n(\RR^d)}}_{\Xi_B}\Big(\underbrace{\frac{Z_n(\RR^d)-Y_n(\RR^d)}{Y_n(\RR^d)}}_\Phi \Big) +\underbrace{\frac{Y_n(B)-c_n}{Y_n(\RR^d)}}_{\Omega} \Bigg|.\] <p>Using $\eqref{eq:conv-in-mean-sup}$, $\eqref{eq:Yn-with-quotient}$, the triangle inequality, and Markov’s inequality, we have \(\sup_B \lvert Z_n(B)-Y_n(B)\rvert \to 0\) in probability. Recall that $c_n$ converges in mean to 0. Also, \(c_n &lt; 1\), so \(Z_n(\RR^d) &gt; 0\) a.s. and thus converges to a positive R.V., i.e., \(1/Z_n(\RR^d) = \mathcal{O}_{\PP}(1)\). Thus,</p> \[\sup_B |\Lambda_B| = \mathcal{o}_\PP (1) \mathcal{O}_\PP(1) = \mathcal{o}_\PP (1).\] <p>Also, \(\sup_B Z_n(B) \in [0, Z_n(\RR^d)]\). So</p> \[\sup_B |\Xi_B| = \mathcal{O}_\PP(1).\] <p>The fact that \(\sup_B \lvert Z_n(B)-Y_n(B)\rvert \to 0\) in probability implies \(\lvert Z_n(\RR^d)-Y_n(\RR^d)\rvert \to 0\) in probability. So \(Y_n(\RR^d)\) also converges to a positive R.V., i.e., \(1/Y_n(\RR^d) = \mathcal{O}_{\PP}(1)\). So</p> \[|\Psi| = \mathcal{o}_\PP(1) \mathcal{O}_\PP(1) = \mathcal{o}_\PP(1)\] <p>and</p> \[\Omega = \mathcal{O}_\PP(1) \mathcal{o}_\PP(1) = \mathcal{o}_\PP(1).\] <p>Hence,</p> \[\sup_B \Bigg| \frac{Z_n(B)}{Z_n(\RR^d)} - \frac{Y_n(B)(1-c_n)}{Y_n(\RR^d)} \Bigg| \leq \sup_B |\Lambda_B| + \sup_B |\Xi_B| \cdot |\Psi|+|\Omega| = \mathcal{o}_\PP(1).\] <p>We are almost done, except that we have not shown $\PP_{\theta_0}[A_n] \to 1$ from <a href="#details-on-step-1">step 1</a>. To this end, note that \(\{Y_n(\RR^d) \geq \frac{\pi(\theta_0+h/\sqrt{n})}{\theta_0} \epsilon_n\} \subset A_n\) for every \(\|h\| &lt;M_n\). Since \(Y_n(\RR^d)\) tends to a postivie R.V. as we argued earlier, we have \(\PP_{\theta_0}[A_n] \geq \PP_{\theta_0}[Y_n(\RR^d)\geq \frac{\pi(\theta_0+h/\sqrt{n})}{\theta_0} \epsilon_n] \to 1\).</p> <h3 id="references">References</h3> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">CUP</abbr> </div> <div id="vaart1998asymptotic" class="col-sm-8"> <div class="title">Asymptotic Statistics</div> <div class="author"> Aad van der Vaart </div> <div class="periodical"> 1998 </div> <div class="periodical"> </div> <div class="links"> <a href="https://www.cambridge.org/core/books/asymptotic-statistics/A3C7DAD3F7E66A1FA60E9C8FE132EE1D" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="szabo2023bayesian" class="col-sm-8"> <div class="title">Bayesian Statistics</div> <div class="author"> Botond Szabó, and Aad van der Vaart </div> <div class="periodical"> 2023 </div> <div class="periodical"> Lecture notes </div> <div class="links"> <a href="https://diamhomes.ewi.tudelft.nl/%7Eavandervaart/books/bayesianstatistics" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li> </ol> </div> </div> </article> <script src="/assets/js/math/environments.js"></script> </div> </div> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Junming Guan. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{macros:{RR:"{\\mathbb{R}}",EE:"{\\mathbb{E}}",PP:"{\\mathbb{P}}",indicator:["{\\mathbb{1}_{#1}}",1]},tags:"ams",inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]]},chtml:{scale:.8}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script>for(var wechatModal=document.getElementById("WeChatMod"),wechatBtn=document.querySelectorAll('[id="WeChatBtn"]'),i=0;i<wechatBtn.length;i++)wechatBtn[i].onclick=function(){wechatModal.style.display="block"};window.onclick=function(t){t.target==wechatModal&&(wechatModal.style.display="none")};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"post-bernstein-von-mises-theorem",title:"Bernstein-von Mises Theorem",description:"Proof of Bernstein-von Mises Theorem",section:"Posts",handler:()=>{window.location.href="/blog/2025/bvm/"}},{id:"post-empirical-bayes-confidence-intervals",title:"Empirical Bayes Confidence Intervals",description:"Constructing confidence intervals for EB estimates",section:"Posts",handler:()=>{window.location.href="/blog/2025/ebci/"}},{id:"post-poisson-f-modeling",title:"Poisson f-modeling",description:"Monotonicity of Poisson posterior mean",section:"Posts",handler:()=>{window.location.href="/blog/2025/poisson-f-modeling/"}},{id:"news-our-paper-on-family-based-gwas-is-out-sparkles-smile",title:'Our paper on family-based GWAS is out! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"social-email",title:"email",section:"Socials",handler:()=>{window.open("mailto:%6A%75%6E%6D%69%6E%67%67%75%61%6E@%75%63%68%69%63%61%67%6F.%65%64%75","_blank")}},{id:"social-x",title:"X",section:"Socials",handler:()=>{window.open("https://twitter.com/JunmingGuan","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>